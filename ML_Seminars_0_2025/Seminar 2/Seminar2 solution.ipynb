{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import libraries & the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:20:46.529933Z",
     "start_time": "2025-01-23T05:20:46.482152Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:47.422526Z",
     "start_time": "2025-01-23T05:19:47.278103Z"
    }
   },
   "outputs": [],
   "source": [
    "# read Bikeshare dataset\n",
    "df_bike = pd.read_csv(\"C:\\\\Users\\\\Darya\\\\Desktop\\\\№7 Lecture support materials, lectures, seminars and labs\\\\Seminars\\\\Machine learning\\\\Seminar 2\\\\Bike.csv\").rename(columns={'cnt' : 'cnt_rental_bike'})\n",
    "\n",
    "# sample 7 random rows of the dataframe\n",
    "df_bike.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : for the column 'weathersit', replace the values such as :  \n",
    "1: 'clear'\\\n",
    "2: 'cloudy'\\\n",
    "3: 'light_rain'\\\n",
    "4: 'heavy_rain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:47.449804Z",
     "start_time": "2025-01-23T05:19:47.304231Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    1: 'clear' ,2: 'cloudy' ,3: 'light_rain' ,4: 'heavy_rain'\n",
    "}\n",
    "df_bike['weathersit'] = df_bike['weathersit'].map(mapping)\n",
    "df_bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Using pandas only, explore your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:47.484571Z",
     "start_time": "2025-01-23T05:19:47.313699Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_bike.info())\n",
    "print()\n",
    "print(df_bike.describe())\n",
    "print()\n",
    "print(df_bike['weathersit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:47.485419Z",
     "start_time": "2025-01-23T05:19:47.334487Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bike.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:48.131408Z",
     "start_time": "2025-01-23T05:19:47.343354Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def draw_box_plots(df):\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    \n",
    "    n = len(numerical_cols)\n",
    "    n_rows = int(np.ceil(n / 3))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, column in enumerate(numerical_cols):\n",
    "        sns.boxplot(data=df[column], ax=axes[i])\n",
    "        axes[i].set_title(f\"Boxplot for {column}\")\n",
    "    \n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_box_plots(df_bike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As we can see: columns casual, registered, cnt_rental_bike have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To resolve this, we will use min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:21:34.023488Z",
     "start_time": "2025-01-23T05:21:33.223931Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_df = df_bike.copy()\n",
    "\n",
    "columns_to_scale = ['casual', 'registered', 'cnt_rental_bike']\n",
    "\n",
    "scaled_df[columns_to_scale] = scaler.fit_transform(scaled_df[columns_to_scale])\n",
    "draw_box_plots(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or we may use a standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:22:21.367219Z",
     "start_time": "2025-01-23T05:22:20.563444Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_df = df_bike.copy()\n",
    "\n",
    "columns_to_scale = ['casual', 'registered', 'cnt_rental_bike']\n",
    "\n",
    "scaled_df[columns_to_scale] = scaler.fit_transform(scaled_df[columns_to_scale])\n",
    "draw_box_plots(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences between scaling methods:\n",
    "\n",
    "Min max:\n",
    "1) Min max scales the values between a specified range, usually [0, 1].\n",
    "2) This technique is useful when you want to transform the data into a bounded range, typically [0, 1]. It’s often used when the model expects data in a specific range\n",
    "3) Sensitive to Outliers\n",
    "4) No Assumptions About Distribution:\n",
    "\n",
    "Standard: \n",
    "1) Standardization does not bound the values to a fixed range.\n",
    "2) typically used when the data follows a Gaussian (normal) distribution\n",
    "3) Not Sensitive to Outliers:\n",
    "4) Assumes Gaussian Distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or we may change the outliers to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:49.475556Z",
     "start_time": "2025-01-23T05:19:49.033094Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def insert_median_values(df, column_name):\n",
    "    median_from_df = df[column_name].median()\n",
    "    return median_from_df\n",
    "\n",
    "def define_big_value_not_normal(df, column):\n",
    "    inter_quantile = df[column].quantile(0.75) - df[column].quantile(0.25)\n",
    "    biggest_threshold = df[column].quantile(0.75) + inter_quantile\n",
    "    smallest_threshold = df[column].quantile(0.25) - inter_quantile\n",
    "    return smallest_threshold, biggest_threshold\n",
    "\n",
    "problem_columns = ['casual', 'registered', 'cnt_rental_bike']\n",
    "\n",
    "for column in problem_columns:\n",
    "    small_val, big_val = define_big_value_not_normal(df_bike, column)\n",
    "    if column != 'revenue':\n",
    "        print(f'In columns {column} detected {len(df_bike[df_bike[column] < small_val])} low-outliers и {len(df_bike[df_bike[column] > big_val])} high-outliers')\n",
    "        \n",
    "        df_bike[column] = df_bike[column].apply(\n",
    "            lambda x: insert_median_values(df_bike, column) \n",
    "            if (x < small_val or x > big_val)\n",
    "            else x\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:50.173245Z",
     "start_time": "2025-01-23T05:19:49.333713Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "draw_box_plots(df_bike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : The dataset has several columns related to date/time:\n",
    "\n",
    "Create a new column `datetime` which will store information about both date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:50.179858Z",
     "start_time": "2025-01-23T05:19:50.173122Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bike['dteday'] = pd.to_datetime(df_bike['dteday'])\n",
    "df_bike['datetime'] = df_bike['dteday'] + pd.to_timedelta(df_bike['hr'], unit='h')\n",
    "df_bike['datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Vizualize the seasonality of rental bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:55.950267Z",
     "start_time": "2025-01-23T05:19:50.187079Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bike['dteday'] = pd.to_datetime(df_bike['dteday'])\n",
    "sns.lineplot(x='dteday', y='cnt_rental_bike', data=df_bike)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Bike Rental Count')\n",
    "plt.title('Bike Rentals Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : What's the datatype of 'Wheathersit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:55.950481Z",
     "start_time": "2025-01-23T05:19:55.946207Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_bike['weathersit'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Count the values of Wheathersit and plot its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.051112Z",
     "start_time": "2025-01-23T05:19:55.956272Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = df_bike['weathersit'].value_counts()\n",
    "print(counter)\n",
    "sns.histplot(df_bike['weathersit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : What's the number of $K$ in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.051386Z",
     "start_time": "2025-01-23T05:19:56.029917Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = df_bike['weathersit'].unique()\n",
    "counter.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Implement your own One-Hot-Encoding algorithm. Encode weathersit column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.138108Z",
     "start_time": "2025-01-23T05:19:56.035149Z"
    }
   },
   "outputs": [],
   "source": [
    "values = df_bike['weathersit'].unique()\n",
    "encoded_df = df_bike.copy()\n",
    "for val in values:\n",
    "    encoded_df[val] = (encoded_df['weathersit'] == val).astype(int)\n",
    "\n",
    "only_encoded = encoded_df[list(values)].astype(float)\n",
    "only_encoded.columns = ['weathersit_' + i for i in only_encoded.columns]\n",
    "only_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Use scikit-learn OHE encoder for the same column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.139064Z",
     "start_time": "2025-01-23T05:19:56.069330Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False) \n",
    "encoded = encoder.fit_transform(df_bike[['weathersit']])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['weathersit']))\n",
    "encoded_df\n",
    "\n",
    "# copy_df = df_bike.copy()\n",
    "# copy_df = pd.concat([copy_df, encoded_df], axis=1)\n",
    "# \n",
    "# copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 : Compare your encoded columns with the SKLearn ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.139204Z",
     "start_time": "2025-01-23T05:19:56.086960Z"
    }
   },
   "outputs": [],
   "source": [
    "((encoded_df['weathersit_clear'] == only_encoded['weathersit_clear']) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((encoded_df['weathersit_cloudy'] == only_encoded['weathersit_cloudy']) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((encoded_df['weathersit_heavy_rain'] == only_encoded['weathersit_heavy_rain']) == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((encoded_df['weathersit_light_rain'] == only_encoded['weathersit_light_rain']) == False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12 : Modify your algorithm to drop one column while encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.140162Z",
     "start_time": "2025-01-23T05:19:56.091984Z"
    }
   },
   "outputs": [],
   "source": [
    "values = df_bike['weathersit'].unique()\n",
    "encoded_df = df_bike.copy()\n",
    "for val in values:\n",
    "    encoded_df[val] = (encoded_df['weathersit'] == val).astype(int)\n",
    "\n",
    "only_encoded = encoded_df[list(values[:-1:])].astype(float)\n",
    "only_encoded.columns = ['weathersit_' + i for i in only_encoded.columns]\n",
    "only_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13 : What are advantages and disadvantages of such encoding of a categorical varable? Does the answer depend on whether it is nominal or ordinal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) No dependency\n",
    "2) No bias \n",
    "3) Handling Non-Numeric Data\n",
    "4) Simplicity and Interpretability\n",
    "\n",
    "For ordinal: \n",
    "1) Loss of Information for Ordinal Data (low, medium, high = 0 or 1)\n",
    "2) Increased Training Time (more features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14 : What can be said about linear dependence of the columns produced by one-hot-encoding? Consider two cases: with and without dropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Dropping a Category Column: \n",
    "1) The sum of the one-hot encoded columns will always be 1\n",
    "2) the columns are not independent\n",
    "A+B+C=1\n",
    "\n",
    "With Dropping a Category Column:\n",
    "1) The columns are linearly dependent. This is because the sum of the one-hot encoded columns for each row is always 1.\n",
    "2) we eliminate the redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 15 : Repeat the steps 7 to 9, for label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.396907Z",
     "start_time": "2025-01-23T05:19:56.111461Z"
    }
   },
   "outputs": [],
   "source": [
    "category_counts = only_encoded.apply(pd.Series.value_counts)\n",
    "print(category_counts)\n",
    "sns.histplot(only_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:19:56.397645Z",
     "start_time": "2025-01-23T05:19:56.316568Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "category_counts.index.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
